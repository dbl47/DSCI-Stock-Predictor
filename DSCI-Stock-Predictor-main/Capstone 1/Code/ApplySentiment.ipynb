{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9969230769230769\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pycorenlp import StanfordCoreNLP\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def get_sentiment(text):\n",
    "    \"\"\"Returns a float from Stanford NLP sentimentValue results\"\"\"\n",
    "    result = nlp.annotate(text, properties={\n",
    "                       'annotators': 'sentiment',\n",
    "                       'outputFormat': 'json',\n",
    "                       'timeout': 5000,\n",
    "                   })\n",
    "    return np.mean([int(i['sentimentValue']) for i in result['sentences']])\n",
    "\n",
    "\"\"\"\n",
    "Paste this in terminal window to start server:\n",
    "\n",
    "cd stanford-corenlp-full-2018-10-05\n",
    "java -mx6g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -timeout 5000\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#Connect to running Stanford NLP server\n",
    "nlp = StanfordCoreNLP('http://localhost:9000')\n",
    "\n",
    "#Read file, get number of headlines/tweets\n",
    "df = pd.read_pickle('stock_prediction_data2.p')\n",
    "df['num_headlines'] = df['NewsHeadlineList'].str.len()\n",
    "df['num_tweets'] = df['TweetList'].str.len()\n",
    "\n",
    "\n",
    "headline_sent = []\n",
    "twitter_sent = []\n",
    "counter = 0\n",
    "\n",
    "#Loop over data to get sentiment score for each headline/tweet that day, then take the mean as that days sentiment\n",
    "for i in df.values.tolist():\n",
    "    today_headline_sent = []\n",
    "    today_twitter_sent = []\n",
    "    headlines, tweets = i[2], i[7]\n",
    "    for h in headlines:\n",
    "        try:\n",
    "            score = get_sentiment(h)\n",
    "            today_headline_sent.append(score)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    #too many tweets, only taking a random 10% sample\n",
    "    sample_size = int(len(tweets) * 0.1)\n",
    "    tweet_samples = random.sample(tweets, sample_size)\n",
    "    for t in tweet_samples:\n",
    "        try:\n",
    "            score = get_sentiment(t)\n",
    "            today_twitter_sent.append(score)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    todays_headline_sent = np.mean(today_headline_sent)\n",
    "    todays_twitter_sent = np.mean(today_twitter_sent)\n",
    "    headline_sent.append(todays_headline_sent)\n",
    "    twitter_sent.append(todays_twitter_sent)\n",
    "    clear_output(wait=True)\n",
    "    print (counter / len(df))\n",
    "    counter += 1\n",
    "    \n",
    "df['headline_sentiment'] = headline_sent\n",
    "df['twitter_sentiment'] = twitter_sent"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
